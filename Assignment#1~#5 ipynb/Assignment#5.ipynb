{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6조 (17011709 정선아, 17011741 문성용, 17011742 김소영)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function, unicode_literals)\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-1m')\n",
    "kf = KFold(n_splits = 5)\n",
    "sim_options = {'name' : 'cosine', 'user_based' : True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Precision & Recall & F1-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/NicolasHug/Surprise/blob/master/examples/precision_recall_at_k.py에서 가져온 코드\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P_R_F(data, algo):\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        precisions, recalls = precision_recall_at_k(predictions, k = 5, threshold = 4)\n",
    "\n",
    "        P = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "        R = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "        F1 = 2 * P * R / (P + R)\n",
    "\n",
    "        print('precision : ', P)\n",
    "        print('recall : ', R)\n",
    "        print('F1 : '  , F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision :  0.8962039644415173\n",
      "recall :  0.2490751859424374\n",
      "F1 :  0.3898126828045115\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision :  0.8911543772438719\n",
      "recall :  0.2487028423850319\n",
      "F1 :  0.38887787489132974\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision :  0.8958947600905677\n",
      "recall :  0.2494088494133466\n",
      "F1 :  0.3901918748102418\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision :  0.89377037405383\n",
      "recall :  0.25096818574626323\n",
      "F1 :  0.39189372513007664\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "precision :  0.8880987899884119\n",
      "recall :  0.2517205559522374\n",
      "F1 :  0.3922599172448734\n"
     ]
    }
   ],
   "source": [
    "algo = KNNWithMeans(k = 40, min_k = 1, simoptions = sim_options)\n",
    "get_P_R_F(data, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.8611101910124881\n",
      "recall :  0.2771596537950983\n",
      "F1 :  0.4193469650613405\n",
      "precision :  0.8609160178896915\n",
      "recall :  0.27210717707825505\n",
      "F1 :  0.413515678001709\n",
      "precision :  0.8611267683466096\n",
      "recall :  0.27760110523686166\n",
      "F1 :  0.4198540286711317\n",
      "precision :  0.8629411764706003\n",
      "recall :  0.2765924951788015\n",
      "F1 :  0.4189135593458251\n",
      "precision :  0.8649314765694208\n",
      "recall :  0.2790423324148288\n",
      "F1 :  0.4219545844589454\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors = 100, n_epochs = 20, biased = False, lr_all = 0.005, reg_all = 0)\n",
    "get_P_R_F(data, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.895736049014749\n",
      "recall :  0.26456336312922696\n",
      "F1 :  0.40847894797351236\n",
      "precision :  0.8949304174950438\n",
      "recall :  0.2653282415822242\n",
      "F1 :  0.40930582530837656\n",
      "precision :  0.8973243870112788\n",
      "recall :  0.2651972224976996\n",
      "F1 :  0.40939958994027487\n",
      "precision :  0.9012170889220201\n",
      "recall :  0.2623175644341266\n",
      "F1 :  0.4063567356770022\n",
      "precision :  0.9001574150787187\n",
      "recall :  0.264476511509726\n",
      "F1 :  0.40883317498230615\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors = 100, n_epochs = 20, biased = False, lr_all = 0.005, reg_all = 0.02)\n",
    "get_P_R_F(data, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision :  0.8807811291570121\n",
      "recall :  0.28089336116659297\n",
      "F1 :  0.42594646586773366\n",
      "precision :  0.8849373309038829\n",
      "recall :  0.2790187150746062\n",
      "F1 :  0.4242670122182881\n",
      "precision :  0.886203181968856\n",
      "recall :  0.28260905579790874\n",
      "F1 :  0.42855308390653163\n",
      "precision :  0.886988231394013\n",
      "recall :  0.28514419886197023\n",
      "F1 :  0.43155456177525325\n",
      "precision :  0.8838940448569345\n",
      "recall :  0.2849378859430448\n",
      "F1 :  0.43095143776027\n"
     ]
    }
   ],
   "source": [
    "algo = SVD(n_factors = 100, n_epochs = 20, biased = True, lr_all = 0.005, reg_all = 0.02)\n",
    "get_P_R_F(data, algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.raw_ratings, columns = ['uid', 'iid', 'rate', 'timestamp'])\n",
    "del df['timestamp']\n",
    "user = list(set(df.uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRating(uid, pred_data): \n",
    "    add = df[df.uid == uid] # 해당 사용자 행만 추출\n",
    "    add['pred'] = 0.0 # 데이터프레임에 예측 레이팅 열 추가\n",
    "    for iid, i in zip(add.iid, add.index):\n",
    "        add.set_value(i, 'pred', pred_data.iloc[int(uid) - 1][int(iid) - 1]) # uid, iid 1부터 시작하므로 -1\n",
    "    \n",
    "    return add\n",
    "\n",
    "def DCG(data):\n",
    "    pred_sort = list(data.sort_values(by = ['pred'], axis = 0, ascending = False).rate)\n",
    "    # 예측 레이팅을 기준으로 내림차순으로 정렬한 실제 레이팅 리스트\n",
    "    dcg = pred_sort[0] # 예측 레이팅이 가장 높은 아이템의 실제 레이팅 저장\n",
    "    for i in range(1, len(pred_sort)): # 리스트 돌며\n",
    "        dcg += pred_sort[i] / np.log2(i + 1) # 순서대로 가중치를 줄여가며 더해주기\n",
    "        \n",
    "    return dcg\n",
    "\n",
    "def IDCG(data):\n",
    "    rate_sort = list(data.sort_values(by = ['rate'], axis = 0, ascending = False).rate)\n",
    "    # 실제 레이팅을 기준으로 내림차순으로 정렬한 실제 레이팅 리스트\n",
    "    idcg = rate_sort[0] # 실제 레이팅이 가장 높은 아이템의 실제 레이팅 저장\n",
    "    for i in range(1, len(rate_sort)): # 리스트 돌며\n",
    "        idcg += rate_sort[i] / np.log2(i + 1) # 순서대로 가중치를 줄여가며 더해주기\n",
    "        \n",
    "    return idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG_oneUser(uid, pred_data): # 한 사용자의 NDCG\n",
    "    table = addRating(uid, pred_data) # 예측 레이팅 열 추가한 데이터프레임\n",
    "    dcg = DCG(table)\n",
    "    idcg = IDCG(table)\n",
    "    \n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG_byUser(user, pred_data): # 모든 사용자의(사용자 ID별) NDCG\n",
    "    NDCG = {} # 딕셔너리 생성\n",
    "    for u in user: # 각 유저를 돌며\n",
    "        value = NDCG_oneUser(u, pred_data) # NDCG 값 구하고\n",
    "        NDCG[u] = value # key로는 user_id, value로는 NDCG 값 저장\n",
    "    return NDCG;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(user, pred_data):\n",
    "    NDCG = NDCG_byUser(user, pred_data)\n",
    "    return sum(NDCG.values()) / len(NDCG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment#4에서 구한 예측 레이팅 불러오기\n",
    "pred_rating_cf_mean = pd.read_csv('pred_rating_cf_mean.csv')\n",
    "pred_rating_svd = pd.read_csv('pred_rating_svd.csv')\n",
    "pred_rating_pmf = pd.read_csv('pred_rating_pmf.csv')\n",
    "pred_rating_pmf_bias = pd.read_csv('pred_rating_pmf_bias.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDCG_CFwM = NDCG(user, pred_rating_cf_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9964565651583643"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG_CFwM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDCG_SVD = NDCG(user, pred_rating_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992619673506265"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG_SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDCG_PMF = NDCG(user, pred_rating_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9879664227885725"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG_PMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDCG_PMFwB = NDCG(user, pred_rating_pmf_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877145321683876"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDCG_PMFwB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
